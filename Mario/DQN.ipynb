{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Mario'nun Kurulumu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alt kısımda ilk satırımızda oyunun kütüphanesini import ediyoruz. İkinci satırında ise bize oyunu oynamamız için bir konsol sağlayacak bir kütüphaneyi import ediyoruz.\n",
    "\n",
    "En alttaki ise diğerlerinden farklı olarak Mario oyunundaki basit hareketleri import ediyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym_super_mario_bros\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alt kısımda oyunumuzu 'env' değişkeni altında başlatıp buna bir JoypadSpace ekliyoruz.\n",
    "\n",
    "JoypadSpace eklememiz oyundaki hamleleri basitleştirip azaltıyor. Normalde ilk satırdaki tanımladığımızda env.action.space 256 iken JoypadeSpace komutu ile bu üstteki SIMPLE_MOVEMENT kısmı ile 7'ye düşüyor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alttaki kısımda ise env'imiz ile oyunu rastgele hamlelerle oynamaya çalışıyoruz. \n",
    "\n",
    "https://pypi.org/project/gym-super-mario-bros/ sitesinden env, hareketler, oynanabilecek versiyonlar ve diğerleri hakkında daha detaylı bilgi edinilebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = True\n",
    "for step in range(3000): \n",
    "    if done: \n",
    "        env.reset()\n",
    "    # Rastgele hareketler yapıyor...\n",
    "    state, reward, done, info = env.step(env.action_space.sample())\n",
    "    # Oyunu ekrana yansıtmak için kullanılıyor...\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Env Hazırlıkları**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alttaki kodlardan ilk satırdaki **FrameStack** aynı anda birden fazla görüntü(frame) tutmamıza yarıyor. Bu aslında modelin şuan için karar vermesinden genel olarak geçmişini de göz önünde bulundurarak karar vermesini sağlıyor.\n",
    "\n",
    "**GrayScaleObservation** ise renklerden dolayı 3 kanaldan alınacak bilgiyi 1 kanala düşürüyor. Bu bizim işlemden tasarruf etmemizi sağlıyor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.wrappers import FrameStack, GrayScaleObservation\n",
    "from stable_baselines3.common.vec_env import VecFrameStack,DummyVecEnv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Görüldüğü üzere **GrayScaleObservation** ile kanalımız 3'ten 1'e düştü..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.reset().shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(env.reset())\n",
    "\n",
    "env=GrayScaleObservation(env,keep_dim=True)\n",
    "env.reset().shape\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(env.reset())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Env'ımıza kaç tane frame tutacağını söylüyoruz. Burada bu değer 4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env=DummyVecEnv([lambda:env])\n",
    "env=VecFrameStack(env,4,channels_order='last')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Eğitim Aşaması**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN bizim reinforcement için kullanacağımız model.\n",
    "\n",
    "BaseCallback'i de import etmemin nedeni modellerin performanslarının farklı olacağından belli bir periyotta en iyi modeli kaydetmek..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Burada callback olarak tanımlıyor ve ne istediğimizi söylüyoruz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaydetmelerimizi yapacağımız yerleri giriyoruz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "callback'imiz için hangi sıklıkla ve nereye kaydedeceğimizi giriyoruz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)\n",
    "# CnnLstmPolicy, MlpPolicy\n",
    "model=DQN('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=1e-6, \n",
    "            batch_size=4,buffer_size=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=1, callback=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elde ettiğimiz değerleri alttaki komut ile görebiliriz.\n",
    "\n",
    "Kodları cmd ile eğitim aşamasında da görebilirsiniz..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd logs/PPO_3\n",
    "!tensorboard --logdir=."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Test Aşaması**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "İstediğimiz modeli seçiyoruz ve çalıştırıyoruz.\n",
    "\n",
    "Modeller genelde 600k 700k nın üzerindeyken daha iyi performans gösteriyor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN.load('./train/best_model_440000')\n",
    "\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "while True: \n",
    "    \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50914b293cc5403024430845130995b35b4e148713b72cf631487f50edb40eec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.11 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
